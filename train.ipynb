{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8ebc95",
   "metadata": {},
   "source": [
    "# Faster Whisper for Small Scale Speech To Text Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e0e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3\n",
      "/opt/anaconda3/bin/python\n",
      "environ({'COMMAND_MODE': 'unix2003', 'CONDA_DEFAULT_ENV': 'base', 'CONDA_EXE': '/opt/anaconda3/bin/conda', 'CONDA_PREFIX': '/opt/anaconda3', 'CONDA_PROMPT_MODIFIER': '(base) ', 'CONDA_PYTHON_EXE': '/opt/anaconda3/bin/python', 'CONDA_SHLVL': '1', 'GSETTINGS_SCHEMA_DIR': '/opt/anaconda3/share/glib-2.0/schemas', 'HOME': '/Users/hehvince', 'HOMEBREW_CELLAR': '/opt/homebrew/Cellar', 'HOMEBREW_PREFIX': '/opt/homebrew', 'HOMEBREW_REPOSITORY': '/opt/homebrew', 'INFOPATH': '/opt/homebrew/share/info:', 'LOGNAME': 'hehvince', 'MAMBA_EXE': '/Users/hehvince/.micromamba/bin/micromamba', 'MAMBA_ROOT_PREFIX': '/Users/hehvince/micromamba', 'MallocNanoZone': '0', 'OLDPWD': '/', 'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined', 'PATH': '/opt/anaconda3/bin:/Users/hehvince/micromamba/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/Users/hehvince/.local/bin:/Users/hehvince/.local/bin', 'PWD': '/', 'SHELL': '/bin/zsh', 'SHLVL': '2', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.N012fu1Yin/Listeners', 'TMPDIR': '/var/folders/cx/t80f8k7j2h1b0cnx64j7nxg00000gn/T/', 'USER': 'hehvince', 'VSCODE_CODE_CACHE_PATH': '/Users/hehvince/Library/Application Support/Code/CachedData/6f17636121051a53c88d3e605c491d22af2ba755', 'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost', 'VSCODE_CWD': '/', 'VSCODE_ESM_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'VSCODE_IPC_HOOK': '/Users/hehvince/Library/Application Support/Code/1.10-main.sock', 'VSCODE_NLS_CONFIG': '{\"userLocale\":\"en-gb\",\"osLocale\":\"en-sg\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/Applications/Visual Studio Code.app/Contents/Resources/app/out/nls.messages.json\",\"locale\":\"en-gb\",\"availableLanguages\":{}}', 'VSCODE_PID': '41791', 'XPC_FLAGS': '0x0', 'XPC_SERVICE_NAME': '0', '_': '/opt/anaconda3/bin/python', '__CFBundleIdentifier': 'com.microsoft.VSCode', '__CF_USER_TEXT_ENCODING': '0x1F5:0x0:0x64', 'ELECTRON_RUN_AS_NODE': '1', 'APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL': '1', 'APPLICATIONINSIGHTS_CONFIGURATION_CONTENT': '{}', 'VSCODE_L10N_BUNDLE_LOCATION': '', 'PYTHONUNBUFFERED': '1', 'GSETTINGS_SCHEMA_DIR_CONDA_BACKUP': '', 'PYTHONIOENCODING': 'utf-8', '_CE_CONDA': '', 'CONDA_ROOT': '/opt/anaconda3', '_CE_M': '', 'CONDA_ALLOW_SOFTLINKS': 'false', 'LC_CTYPE': 'C.UTF-8', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHON_FROZEN_MODULES': 'on', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline'})\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.prefix)\n",
    "print(sys.executable)\n",
    "import os\n",
    "print(os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17bab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time, statistics, math, os, tempfile, pathlib\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "from datasets import load_dataset, Audio, concatenate_datasets\n",
    "from jiwer import wer\n",
    "from faster_whisper import WhisperModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2548461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small.en Loaded.\n"
     ]
    }
   ],
   "source": [
    "# ---- Configure model ----\n",
    "MODEL_NAME = \"small.en\"       # use \"small\" if you need multilingual\n",
    "COMPUTE_TYPE = \"int8\"         # int8 for low RAM & good speed/accuracy balance\n",
    "DEVICE = \"auto\"               # auto -> Metal on Apple Silicon; else CPU\n",
    "\n",
    "\n",
    "model = WhisperModel(MODEL_NAME, device=DEVICE, compute_type=COMPUTE_TYPE)\n",
    "print(MODEL_NAME, \"Loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_array_to_text(audio_array: np.ndarray, sample_rate: int, beam_size=5, vad_filter=True) -> Tuple[str, float]:\n",
    "    \"\"\"Write an audio array to a temp WAV and transcribe. Returns (text, processing_time_seconds)\"\"\"\n",
    "    # Ensure mono float32 at 16k if needed:\n",
    "    if audio_array.ndim > 1:\n",
    "        audio_array = np.mean(audio_array, axis=1)\n",
    "    if sample_rate != 16000:\n",
    "        # librosa can resample but to avoid extra deps, let faster-whisper handle resampling from file.\n",
    "        pass\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as tmp:\n",
    "        sf.write(tmp.name, audio_array, sample_rate)\n",
    "        t0 = time.perf_counter()\n",
    "        segments, info = model.transcribe(tmp.name, vad_filter=vad_filter, beam_size=beam_size)\n",
    "        hyp = \"\".join(seg.text for seg in segments).strip()\n",
    "        dt = time.perf_counter() - t0\n",
    "    return hyp, dt\n",
    "\n",
    "def eval_dataset(dataset, max_items=None, beam_size=5, vad_filter=True, verbose_every=25):\n",
    "    \"\"\"Evaluate a HuggingFace dataset that has fields: audio[array, sampling_rate], text.\n",
    "\n",
    "    Returns dict with refs, hyps, proc_times, audio_durs, rtf_list, and WER.\n",
    "\n",
    "    If max_items is None, processing entire split (can take long).\n",
    "    \"\"\"\n",
    "\n",
    "    refs, hyps = [], []\n",
    "    proc_times, audio_durs, rtf_list = [], [], []\n",
    "    n = len(dataset) if hasattr(dataset, \"__len__\") else None\n",
    "    count = 0\n",
    "    iterator = dataset if not n else range(n)\n",
    "\n",
    "    for i, item in enumerate(iterator):\n",
    "        \n",
    "        if i < len(dataset):\n",
    "            rec = item if not n else dataset[i]\n",
    "        else:\n",
    "            print(f\"Index {i} out of bounds\")\n",
    "\n",
    "        rec = item if not n else dataset[i]\n",
    "        audio = rec[\"audio\"]\n",
    "        arr = audio[\"array\"].astype(np.float32)\n",
    "        sr = audio[\"sampling_rate\"]\n",
    "        duration = len(arr) / float(sr)\n",
    "        ref = rec[\"text\"].strip().lower()\n",
    "\n",
    "        hyp, dt = transcribe_array_to_text(arr, sr, beam_size=beam_size, vad_filter=vad_filter)\n",
    "        hyp = hyp.strip().lower()\n",
    "\n",
    "        refs.append(ref); hyps.append(hyp)\n",
    "        proc_times.append(dt); audio_durs.append(duration)\n",
    "        rtf = dt / max(1e-9, duration)\n",
    "        rtf_list.append(rtf)\n",
    "\n",
    "        count += 1\n",
    "        if verbose_every and (count % verbose_every == 0):\n",
    "            print(f\"[{count}] dur={duration:.1f}s  time={dt:.2f}s  RTF={rtf:.2f}\")\n",
    "        if max_items is not None and count >= max_items:\n",
    "            break\n",
    "\n",
    "    metric = wer(refs, hyps)\n",
    "    return {\n",
    "        \"refs\": refs,\n",
    "        \"hyps\": hyps,\n",
    "        \"proc_times\": proc_times,\n",
    "        \"audio_durs\": audio_durs,\n",
    "        \"rtf_list\": rtf_list,\n",
    "        \"wer\": metric\n",
    "    }\n",
    "\n",
    "def plot_latency_histogram(rtf_list: List[float]):\n",
    "    \"\"\"Plot a simple histogram of Real-Time Factor (RTF). Lower is better (<1 == faster than real-time).\"\"\"\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(rtf_list, bins=20)\n",
    "    plt.title(\"Per-file Real-Time Factor (RTF)\")\n",
    "    plt.xlabel(\"RTF (processing_time / audio_duration)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d17df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading LibriSpeech splits (this can take minutes the first time)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302b801a968e4fabbd2153e9f835d8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4008549930ad4dadac0029e2bed3ccb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758f9ece228d42278f2cdabbb440f960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f325a11f3b6e436d9b21128f6f1ec26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in the dataset: 5323\n",
      "Dataset columns: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id']\n",
      "Evaluating... (MAX_ITEMS= 50 )\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not load libtorchcodec. Likely causes:\n          1. FFmpeg is not properly installed in your environment. We support\n             versions 4, 5, 6 and 7.\n          2. The PyTorch version (2.8.0) is not compatible with\n             this version of TorchCodec. Refer to the version compatibility\n             table:\n             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n          3. Another runtime dependency; see exceptions below.\n        The following exceptions were raised as we tried to load libtorchcodec:\n        \n[start of libtorchcodec loading traceback]\nFFmpeg version 7: dlopen(/opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core7.dylib, 0x0006): Library not loaded: @rpath/libavutil.59.dylib\n  Referenced from: <7706FFE4-9BB3-3BCA-880F-8416ADA3BD4A> /opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core7.dylib\n  Reason: tried: '/opt/anaconda3/lib/python3.12/lib-dynload/../../libavutil.59.dylib' (no such file), '/opt/anaconda3/bin/../lib/libavutil.59.dylib' (no such file)\nFFmpeg version 6: dlopen(/opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core6.dylib, 0x0006): Library not loaded: @rpath/libavutil.58.dylib\n  Referenced from: <724DA566-18E0-3A5D-A6EF-CD214BDD9FA1> /opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core6.dylib\n  Reason: tried: '/opt/anaconda3/lib/python3.12/lib-dynload/../../libavutil.58.dylib' (no such file), '/opt/anaconda3/bin/../lib/libavutil.58.dylib' (no such file)\nFFmpeg version 5: dlopen(/opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core5.dylib, 0x0006): Library not loaded: @rpath/libavutil.57.dylib\n  Referenced from: <B30E8984-8BA6-39EC-8B21-07BBC8AECC80> /opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core5.dylib\n  Reason: tried: '/opt/anaconda3/lib/python3.12/lib-dynload/../../libavutil.57.dylib' (no such file), '/opt/anaconda3/bin/../lib/libavutil.57.dylib' (no such file)\nFFmpeg version 4: dlopen(/opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core4.dylib, 0x0006): Library not loaded: @rpath/libavutil.56.dylib\n  Referenced from: <456702AB-221D-3ECD-860E-E97F76E6F6DC> /opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core4.dylib\n  Reason: tried: '/opt/anaconda3/lib/python3.12/lib-dynload/../../libavutil.56.dylib' (no such file), '/opt/anaconda3/bin/../lib/libavutil.56.dylib' (no such file)\n[end of libtorchcodec loading traceback].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m MAX_ITEMS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m   \u001b[38;5;66;03m# set to None to run all files in dev+test (≈10 hours total)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating... (MAX_ITEMS=\u001b[39m\u001b[38;5;124m\"\u001b[39m, MAX_ITEMS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m results \u001b[38;5;241m=\u001b[39m eval_dataset(ds, max_items\u001b[38;5;241m=\u001b[39mMAX_ITEMS, beam_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, vad_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m== LibriSpeech results ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWER:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m, in \u001b[0;36meval_dataset\u001b[0;34m(dataset, max_items, beam_size, vad_filter, verbose_every)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iterator):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset):\n\u001b[0;32m---> 35\u001b[0m         rec \u001b[38;5;241m=\u001b[39m item \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;28;01melse\u001b[39;00m dataset[i]\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:2859\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolars\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2858\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[0;32m-> 2859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(key)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:2841\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2839\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2840\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2841\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2842\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2843\u001b[0m )\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py:665\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    664\u001b[0m     pa_table_to_format \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mdrop(col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn_names \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m format_columns)\n\u001b[0;32m--> 665\u001b[0m     formatted_output \u001b[38;5;241m=\u001b[39m formatter(pa_table_to_format, query_type\u001b[38;5;241m=\u001b[39mquery_type)\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_all_columns:\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_output, MutableMapping):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py:410\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py:459\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    458\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m--> 459\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py:223\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mdecode_example(row, token_per_repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_per_repo_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/features/features.py:2093\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \n\u001b[1;32m   2081\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2089\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   2090\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2092\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m-> 2093\u001b[0m         column_name: decode_nested_example(feature, value, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id)\n\u001b[1;32m   2094\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2095\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[1;32m   2096\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[1;32m   2097\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[1;32m   2098\u001b[0m         )\n\u001b[1;32m   2099\u001b[0m     }\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/features/features.py:1405\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[0;32m-> 1405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode_example(obj, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id) \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/features/audio.py:170\u001b[0m, in \u001b[0;36mAudio.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode example audio file into audio data.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    `torchcodec.decoders.AudioDecoder`\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mTORCHCODEC_AVAILABLE:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchcodec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo support decoding audio data, please install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorchcodec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/features/_torchcodec.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchcodec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder \u001b[38;5;28;01mas\u001b[39;00m _AudioDecoder\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAudioDecoder\u001b[39;00m(_AudioDecoder):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchcodec/__init__.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Note: usort wants to put Frame and FrameBatch after decoders and samplers,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# but that results in circular import.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSamples, Frame, FrameBatch  \u001b[38;5;66;03m# usort:skip # noqa\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decoders, samplers  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Note that version.py is generated during install.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchcodec/decoders/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioStreamMetadata, VideoStreamMetadata\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_audio_decoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioDecoder  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_video_decoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoDecoder  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchcodec/_core/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     AudioStreamMetadata,\n\u001b[1;32m     10\u001b[0m     ContainerMetadata,\n\u001b[1;32m     11\u001b[0m     get_container_metadata,\n\u001b[1;32m     12\u001b[0m     get_container_metadata_from_header,\n\u001b[1;32m     13\u001b[0m     VideoStreamMetadata,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     _add_video_stream,\n\u001b[1;32m     17\u001b[0m     _get_key_frame_indices,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     seek_to_pts,\n\u001b[1;32m     39\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchcodec/_core/_metadata.py:16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Union\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchcodec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     _get_container_json_metadata,\n\u001b[1;32m     18\u001b[0m     _get_stream_json_metadata,\n\u001b[1;32m     19\u001b[0m     create_from_file,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     23\u001b[0m SPACES \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStreamMetadata\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchcodec/_core/ops.py:84\u001b[0m\n\u001b[1;32m     64\u001b[0m     traceback \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[start of libtorchcodec loading traceback]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFFmpeg version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v, e \u001b[38;5;129;01min\u001b[39;00m exceptions)\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[end of libtorchcodec loading traceback].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCould not load libtorchcodec. Likely causes:\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124m          1. FFmpeg is not properly installed in your environment. We support\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m load_torchcodec_shared_libraries()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Note: We use disallow_in_graph because PyTorch does constant propagation of\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# factory functions.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m create_from_file \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisallow_in_graph(\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchcodec_ns\u001b[38;5;241m.\u001b[39mcreate_from_file\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m     91\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torchcodec/_core/ops.py:69\u001b[0m, in \u001b[0;36mload_torchcodec_shared_libraries\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         exceptions\u001b[38;5;241m.\u001b[39mappend((ffmpeg_major_version, e))\n\u001b[1;32m     64\u001b[0m traceback \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[start of libtorchcodec loading traceback]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFFmpeg version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v, e \u001b[38;5;129;01min\u001b[39;00m exceptions)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[end of libtorchcodec loading traceback].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCould not load libtorchcodec. Likely causes:\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124m      1. FFmpeg is not properly installed in your environment. We support\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124m         versions 4, 5, 6 and 7.\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124m      2. The PyTorch version (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is not compatible with\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124m         this version of TorchCodec. Refer to the version compatibility\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124m         table:\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124m         https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124m      3. Another runtime dependency; see exceptions below.\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124m    The following exceptions were raised as we tried to load libtorchcodec:\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not load libtorchcodec. Likely causes:\n          1. FFmpeg is not properly installed in your environment. We support\n             versions 4, 5, 6 and 7.\n          2. The PyTorch version (2.8.0) is not compatible with\n             this version of TorchCodec. Refer to the version compatibility\n             table:\n             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n          3. Another runtime dependency; see exceptions below.\n        The following exceptions were raised as we tried to load libtorchcodec:\n        \n[start of libtorchcodec loading traceback]\nFFmpeg version 7: dlopen(/opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core7.dylib, 0x0006): Library not loaded: @rpath/libavutil.59.dylib\n  Referenced from: <7706FFE4-9BB3-3BCA-880F-8416ADA3BD4A> /opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core7.dylib\n  Reason: tried: '/opt/anaconda3/lib/python3.12/lib-dynload/../../libavutil.59.dylib' (no such file), '/opt/anaconda3/bin/../lib/libavutil.59.dylib' (no such file)\nFFmpeg version 6: dlopen(/opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core6.dylib, 0x0006): Library not loaded: @rpath/libavutil.58.dylib\n  Referenced from: <724DA566-18E0-3A5D-A6EF-CD214BDD9FA1> /opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core6.dylib\n  Reason: tried: '/opt/anaconda3/lib/python3.12/lib-dynload/../../libavutil.58.dylib' (no such file), '/opt/anaconda3/bin/../lib/libavutil.58.dylib' (no such file)\nFFmpeg version 5: dlopen(/opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core5.dylib, 0x0006): Library not loaded: @rpath/libavutil.57.dylib\n  Referenced from: <B30E8984-8BA6-39EC-8B21-07BBC8AECC80> /opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core5.dylib\n  Reason: tried: '/opt/anaconda3/lib/python3.12/lib-dynload/../../libavutil.57.dylib' (no such file), '/opt/anaconda3/bin/../lib/libavutil.57.dylib' (no such file)\nFFmpeg version 4: dlopen(/opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core4.dylib, 0x0006): Library not loaded: @rpath/libavutil.56.dylib\n  Referenced from: <456702AB-221D-3ECD-860E-E97F76E6F6DC> /opt/anaconda3/lib/python3.12/site-packages/torchcodec/libtorchcodec_core4.dylib\n  Reason: tried: '/opt/anaconda3/lib/python3.12/lib-dynload/../../libavutil.56.dylib' (no such file), '/opt/anaconda3/bin/../lib/libavutil.56.dylib' (no such file)\n[end of libtorchcodec loading traceback]."
     ]
    }
   ],
   "source": [
    "# ===== Baseline on LibriSpeech: dev-clean (validation) and test-clean =====\n",
    "from datasets import load_dataset, Audio, concatenate_datasets\n",
    "import statistics, numpy as np\n",
    "\n",
    "print(\"Downloading LibriSpeech splits (this can take minutes the first time)...\")\n",
    "ds_dev = load_dataset(\"openslr/librispeech_asr\", \"clean\", split=\"validation\")\n",
    "ds_test = load_dataset(\"openslr/librispeech_asr\", \"clean\", split=\"test\")\n",
    "\n",
    "# IMPORTANT: ensure we get NumPy arrays (not torch tensors)\n",
    "ds_dev = ds_dev.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "ds_test = ds_test.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "# Merge the two clean splits (~10h total if you later run all items)\n",
    "ds = concatenate_datasets([ds_dev, ds_test])\n",
    "\n",
    "# Print the number of examples in the dataset (length of the dataset)\n",
    "print(f\"Number of items in the dataset: {len(ds)}\")\n",
    "\n",
    "# Print the column names to inspect the structure\n",
    "print(f\"Dataset columns: {ds.column_names}\")\n",
    "\n",
    "# You can keep this small for quick sanity checks and increase later\n",
    "MAX_ITEMS = 50   # set to None to run all files in dev+test (≈10 hours total)\n",
    "print(\"Evaluating... (MAX_ITEMS=\", MAX_ITEMS, \")\")\n",
    "results = eval_dataset(ds, max_items=MAX_ITEMS, beam_size=5, vad_filter=True)\n",
    "\n",
    "print(\"\\n== LibriSpeech results ==\")\n",
    "print(\"WER:\", results[\"wer\"])\n",
    "rtf = results[\"rtf_list\"]\n",
    "print(f\"RTF  mean={statistics.mean(rtf):.2f}  median={statistics.median(rtf):.2f}  p90={np.percentile(rtf,90):.2f}\")\n",
    "\n",
    "# Tiny latency chart (RTF histogram)\n",
    "plot_latency_histogram(results[\"rtf_list\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe85488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Optional realism pass: People's Speech (MLCommons) ~10 hours via streaming =====\n",
    "# This will *stream* the dataset and process until ~10 hours of audio are seen, without downloading everything.\n",
    "# You can reduce TARGET_HOURS to 5 if you're short on time/disk.\n",
    "TARGET_HOURS = 5\n",
    "MAX_ITEMS = None   # or cap number of utterances to a fixed integer\n",
    "\n",
    "print(\"Preparing People's Speech streaming loader...\")\n",
    "ds_ps = load_dataset(\"MLCommons/peoples_speech\", \"clean\", split=\"train\", streaming=True)\n",
    "ds_ps = ds_ps.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "refs, hyps, proc_times, audio_durs, rtf_list = [], [], [], [], []\n",
    "seen_sec = 0.0\n",
    "count = 0\n",
    "\n",
    "for rec in ds_ps:\n",
    "    arr = rec[\"audio\"][\"array\"].astype(np.float32)\n",
    "    sr = rec[\"audio\"][\"sampling_rate\"]\n",
    "    duration = rec.get(\"duration_ms\", len(arr) / sr * 1000) / 1000.0\n",
    "    ref = rec.get(\"text\", \"\").strip().lower()\n",
    "\n",
    "    hyp, dt = transcribe_array_to_text(arr, sr, beam_size=5, vad_filter=True)\n",
    "    hyp = hyp.strip().lower()\n",
    "\n",
    "    refs.append(ref); hyps.append(hyp)\n",
    "    proc_times.append(dt); audio_durs.append(duration)\n",
    "    rtf_list.append(dt / max(1e-9, duration))\n",
    "\n",
    "    seen_sec += duration\n",
    "    count += 1\n",
    "    if count % 25 == 0:\n",
    "        print(f\"[{count}] cum_dur={seen_sec/3600:.2f}h  last_dur={duration:.1f}s  last_time={dt:.2f}s\")\n",
    "\n",
    "    if (MAX_ITEMS is not None and count >= MAX_ITEMS) or (seen_sec >= TARGET_HOURS * 3600):\n",
    "        break\n",
    "\n",
    "print(\"\\n== People's Speech ~%.2f hours summary ==\" % (seen_sec/3600))\n",
    "try:\n",
    "    print(\"WER:\", wer(refs, hyps))\n",
    "except Exception as e:\n",
    "    print(\"WER could not be computed (maybe empty references). Error:\", e)\n",
    "if rtf_list:\n",
    "    print(f\"RTF  mean={statistics.mean(rtf_list):.2f}  median={statistics.median(rtf_list):.2f}\")\n",
    "else:\n",
    "    print(\"No items processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
